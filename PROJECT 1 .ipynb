{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the dataset\n",
    "train = pd.read_csv(\"C:\\\\Users\\\\PUNEET SINGH\\\\titanic train.csv\")\n",
    "test = pd.read_csv(\"C:\\\\Users\\\\PUNEET SINGH\\\\titanic test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### checking for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"shape of the  training data set :\" ,train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing the missing value with mean of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Age'] = train['Age'].replace(np.NaN,train['Age'].mean())\n",
    "train['Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the unwanted features from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train.drop(['PassengerId'],axis=1)\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['Name','Parch','Ticket'],axis=1)\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x='Sex')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency          # finding the chi2_contingency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dat = [\"Sex\",\"Embarked\"]                  # choosing the categorical data\n",
    "for i in cat_dat:\n",
    "    print(i)\n",
    "    chi2,p,dof,ex = chi2_contingency(pd.crosstab(train['Survived'],train[i]))\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding independent variable\n",
    "# importing the libraries\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an object\n",
    "ct = ColumnTransformer(transformers=['OneHotEncoder',OneHotEncoder(categories='auto'),[2,7]],remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the object and then tranform it\n",
    "x = np.array(ct.fit_transform(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries for decision tree\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "#Divide data into train and test\n",
    "X = train.values[:, 1:7]\n",
    "Y = train.values[:,0]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, Y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree\n",
    "C50_model = tree.DecisionTreeClassifier(criterion='entropy').fit(X_train, y_train)\n",
    "\n",
    "#predict new test cases\n",
    "C50_Predictions = C50_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build confusion matrix\n",
    "# from sklearn.metrics import confusion_matrix \n",
    "# CM = confusion_matrix(y_test, y_pred)\n",
    "CM = pd.crosstab(y_test, C50_Predictions)\n",
    "\n",
    "#let us save TP, TN, FP, FN\n",
    "TN = CM.iloc[0,0]\n",
    "FN = CM.iloc[1,0]\n",
    "TP = CM.iloc[1,1]\n",
    "FP = CM.iloc[0,1]\n",
    "\n",
    "#check accuracy of model\n",
    "#accuracy_score(y_test, y_pred)*100\n",
    "((TP+TN)*100)/(TP+TN+FP+FN)\n",
    "\n",
    "#False Negative rate \n",
    "(FN*100)/(FN+TP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RF_model = RandomForestClassifier(n_estimators = 20).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_Predictions = RF_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build confusion matrix\n",
    "# from sklearn.metrics import confusion_matrix \n",
    "# CM = confusion_matrix(y_test, y_pred)\n",
    "CM = pd.crosstab(y_test, RF_Predictions)\n",
    "\n",
    "#let us save TP, TN, FP, FN\n",
    "TN = CM.iloc[0,0]\n",
    "FN = CM.iloc[1,0]\n",
    "TP = CM.iloc[1,1]\n",
    "FP = CM.iloc[0,1]\n",
    "\n",
    "#check accuracy of model\n",
    "#accuracy_score(y_test, y_pred)*100\n",
    "((TP+TN)*100)/(TP+TN+FP+FN)\n",
    "\n",
    "#False Negative rate \n",
    "(FN*100)/(FN+TP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create logistic data. Save target variable first\n",
    "train_logit = pd.DataFrame(train['Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add continous variables\n",
    "cnames= [\"Age\",\"Fare\"]\n",
    "train_logit = train_logit.join(train[cnames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_logit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create dummies for categorical variables\n",
    "cat_dat = [\"Sex\",\"Embarked\"]                  # choosing the categorical data\n",
    "\n",
    "for i in cat_names:\n",
    "    temp = pd.get_dummies(train[i], prefix = i)\n",
    "    train_logit = train_logit.join(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sample_Index = np.random.rand(len(train_logit)) < 0.8\n",
    "\n",
    "train1 = train_logit[Sample_Index]\n",
    "test1 = train_logit[~Sample_Index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select column indexes for independent variables\n",
    "train_cols = train1.columns[1:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Built Logistic Regression\n",
    "import statsmodels.api as sm\n",
    "\n",
    "logit = sm.Logit(train1['responded'], train1[train_cols]).fit()\n",
    "\n",
    "logit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict test data\n",
    "test1['Actual_prob'] = logit.predict(test1[train_cols])\n",
    "\n",
    "test1['ActualVal'] = 1\n",
    "test1.loc[test1.Actual_prob < 0.5, 'ActualVal'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build confusion matrix\n",
    "CM = pd.crosstab(test['responded'], test['ActualVal'])\n",
    "\n",
    "#let us save TP, TN, FP, FN\n",
    "TN = CM.iloc[0,0]\n",
    "FN = CM.iloc[1,0]\n",
    "TP = CM.iloc[1,1]\n",
    "FP = CM.iloc[0,1]\n",
    "\n",
    "#check accuracy of model\n",
    "#accuracy_score(y_test, y_pred)*100\n",
    "((TP+TN)*100)/(TP+TN+FP+FN)\n",
    "\n",
    "(FN*100)/(FN+TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
